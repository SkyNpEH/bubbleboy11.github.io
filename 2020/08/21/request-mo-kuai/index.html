<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"bubbleboy11.github.io","root":"/","images":"/images","scheme":"Muse","version":"8.6.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>
<meta name="description" content="urllib 是 Python 标准库中用于网络请求的库。该库有四个模块，分别是urllib.request，urllib.error，urllib.parse，urllib.robotparser。其中urllib.request，urllib.error两个库在爬虫程序中应用比较频繁。urllib一般要先构建get或者post请求，然后再发起请求。 requests模块 基于HTTP请求的模块">
<meta property="og:type" content="article">
<meta property="og:title" content="request模块">
<meta property="og:url" content="https://bubbleboy11.github.io/2020/08/21/request-mo-kuai/index.html">
<meta property="og:site_name" content="外心人D的博客">
<meta property="og:description" content="urllib 是 Python 标准库中用于网络请求的库。该库有四个模块，分别是urllib.request，urllib.error，urllib.parse，urllib.robotparser。其中urllib.request，urllib.error两个库在爬虫程序中应用比较频繁。urllib一般要先构建get或者post请求，然后再发起请求。 requests模块 基于HTTP请求的模块">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-08-20T16:21:41.000Z">
<meta property="article:modified_time" content="2021-07-31T08:45:38.567Z">
<meta property="article:author" content="外心人D">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://bubbleboy11.github.io/2020/08/21/request-mo-kuai/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://bubbleboy11.github.io/2020/08/21/request-mo-kuai/","path":"2020/08/21/request-mo-kuai/","title":"request模块"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>request模块 | 外心人D的博客</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="外心人D的博客" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">外心人D的博客</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Response%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%B1%9E%E6%80%A7"><span class="nav-text">Response对象的属性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Requests%E5%BA%93%E7%9A%84%E5%BC%82%E5%B8%B8"><span class="nav-text">Requests库的异常</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">外心人D</p>
  <div class="site-description" itemprop="description">本博客大多内容为慕课和网上博客，并非原创</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">351</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



          </div>
        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://bubbleboy11.github.io/2020/08/21/request-mo-kuai/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="外心人D">
      <meta itemprop="description" content="本博客大多内容为慕课和网上博客，并非原创">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="外心人D的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          request模块
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2020-08-20 16:21:41" itemprop="dateCreated datePublished" datetime="2020-08-20T16:21:41Z">2020-08-20</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-07-31 08:45:38" itemprop="dateModified" datetime="2021-07-31T08:45:38Z">2021-07-31</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>urllib 是 Python 标准库中用于网络请求的库。该库有四个模块，分别是urllib.request，urllib.error，urllib.parse，urllib.robotparser。其中urllib.request，urllib.error两个库在爬虫程序中应用比较频繁。urllib一般要先构建get或者post请求，然后再发起请求。</p>
<p>requests模块 基于HTTP请求的模块第三方的Python库，<br>小规模，数据量小，速度不敏感、爬取网页<br>支持HTTP连接保持和连接池，支持使用cookie保持会话，<br>支持文件上传，支持自动确定响应内容的编码，<br>支持国际化的 URL 和 POST 数据自动编码。</p>
<p>requests可以直接构建常用的get和post请求并发起，<br>使用了urllib3，多次请求重复使用一个socket，<br>“connection”:”keep-alive”，说明多次请求使用一个连接，消耗更少的资源</p>
<p>作用：模拟浏览器发送HTTP请求。用于爬虫或接口的测试<br>如何使用：</p>
<ul>
<li><p>指定url</p>
</li>
<li><p>发起请求</p>
</li>
<li><p>获取响应数据</p>
</li>
<li><p>持久化存储</p>
</li>
<li><p><code>requests.request()</code>    构造一个请求，支撑以下各方法的基础方法</p>
</li>
<li><p><code>requests.head()</code>    获取HTML网页头信息的方法，对应于HTTP的HEAD</p>
</li>
<li><p><code>requests.put()</code>    向HTML网页提交PUT请求的方法，对应于HTTP的PUT</p>
</li>
<li><p><code>requests.patch()</code>    向HTML网页提交局部修改请求，对应于HTTP的PATCH</p>
</li>
<li><p><code>requests.delete()</code>    向HTML网页提交删除请求，对应于HTTP的DELETE</p>
</li>
<li><p><code>requests.post()</code>    向HTML网页提交POST请求的方法，对应于HTTP的POST</p>
</li>
<li><p><code>requests.get(url, params=None, **kwarge)</code> 构造一个向服务器请求资源的requests对象，返回一个包含服务器资源的requests对象，获取HTML网页的主要方法，对应于HTTP的GET</p>
</li>
</ul>
<p>Requests方法的13个访问控制参数<br>参数名    说明<br><code>url</code>:获取页面的url链接<br><code>params</code>字典或字节序列，作为参数增加到url中<br><code>body</code>字典或字节序列<br><code>s</code>：12个控制访问的参数<br><code>data</code>    字典、字节序列或文件对象，作为Request的内容<br><code>json</code>    JSON格式的数据，作为Request的内容<br><code>headers</code>字典、HTTP定制头<br><code>cookies</code>字典或CookieJar，Request中的cookie<br><code>auth</code>    元组，支持HTTP认证功能<br><code>files</code>    字典类型，传输文件<br><code>timeout</code>    设定超时时间，秒为单位<br><code>proxies</code>    字典类型，设定访问代理服务器，可以增加登录认证<br><code>allow_redirects</code>    True/False,默认为True，重定向开关<br><code>stream</code>默认为True，获取内容立即下载开关<br><code>verify</code>默认为True，认证SSL证书开关<br><code>cert</code>    本地SSL证书路径</p>
<p>Request:构造一个向服务器请求资源的Request对象<br>Response：返回一个包含服务器资源的Response对象</p>
<h3 id="Response对象的属性"><a href="#Response对象的属性" class="headerlink" title="Response对象的属性"></a>Response对象的属性</h3><p><code>r.status_code</code>    HTTP请求的返回状态码<br><code>r.text</code>    HTTP响应内容的字符串形式，即 url对应的页面内容<br><code>r.encoding</code>    从HTTP header中猜测的响应内容编码方式，如果header中不存在charset字段，则认为编码为 ISO-8859-1<br><code>r.apparent_encoding</code>    从内容中分析出的响应内容编码方式（备选编码方式）<br><code>r.content</code>    HTTP响应内容的 byte 类型  二进制形式<br><code>r.content.decode()</code>    </p>
<h3 id="Requests库的异常"><a href="#Requests库的异常" class="headerlink" title="Requests库的异常"></a>Requests库的异常</h3><p><code>requests.ConnectionError</code>    网络连接异常，如DNS查询失败、拒绝连接等<br><code>requests.HTTPError</code>    HTTP错误异常<br><code>requests.URLRequired</code>    URL缺失异常<br><code>requests.TooManyRedirects</code>    超过最大重定向次数，产生重定向异常<br><code>requests.ConnectTimeout</code>    连接远程服务器超时异常<br><code>requests.Timeout</code>    请求URL超时，产生异常</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 . 组装请求</span></span><br><span class="line">url1 = <span class="string">"http://api.tianapi.com/txapi/aqi/index?key=4dce7e012c6391364928602666813641&amp;area=上海"</span></span><br><span class="line">url2 = <span class="string">"http://api.tianapi.com/txapi/aqi/index"</span></span><br><span class="line">url3 = <span class="string">"http://api.tianapi.com/txapi/aqi/index"</span></span><br><span class="line">params = {<span class="string">"key"</span>: <span class="string">"4dce7e012c6391364928602666813641"</span>, <span class="string">"area"</span>: <span class="string">"上海"</span>}</span><br><span class="line">data = {<span class="string">"key"</span>: <span class="string">"4dce7e012c6391364928602666813641"</span>, <span class="string">"area"</span>: <span class="string">"上海"</span>}</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 发送请求，获取响应</span></span><br><span class="line">res1 = requests.get(url=url1)</span><br><span class="line">res2 = requests.get(url=url2, params=params)</span><br><span class="line">res3 = requests.post(url=url3, data=data)</span><br><span class="line"><span class="comment"># 3. 解析响应</span></span><br><span class="line">print(res1.text)</span><br><span class="line">print(res2.text)</span><br><span class="line">print(res3.text)</span><br><span class="line">---</span><br><span class="line">{<span class="string">"code"</span>:<span class="number">200</span>,<span class="string">"msg"</span>:<span class="string">"success"</span>,<span class="string">"newslist"</span>:[{<span class="string">"area"</span>:<span class="string">"上海"</span>,<span class="string">"area_code"</span>:<span class="string">"shanghai"</span>,<span class="string">"so2"</span>:<span class="string">"5"</span>,<span class="string">"o3"</span>:<span class="string">"36"</span>,<span class="string">"pm2_5"</span>:<span class="string">"49"</span>,<span class="string">"primary_pollutant"</span>:<span class="string">"颗粒物(PM2.5)"</span>,<span class="string">"co"</span>:<span class="string">"0.7"</span>,<span class="string">"num"</span>:<span class="string">"231"</span>,<span class="string">"no2"</span>:<span class="string">"71"</span>,<span class="string">"quality"</span>:<span class="string">"良好"</span>,<span class="string">"aqi"</span>:<span class="string">"68"</span>,<span class="string">"pm10"</span>:<span class="string">"57"</span>,<span class="string">"o3_8h"</span>:<span class="string">"52"</span>,<span class="string">"time"</span>:<span class="string">"2021-04-27 20:40:10.642"</span>}]}</span><br><span class="line">{<span class="string">"code"</span>:<span class="number">200</span>,<span class="string">"msg"</span>:<span class="string">"success"</span>,<span class="string">"newslist"</span>:[{<span class="string">"area"</span>:<span class="string">"上海"</span>,<span class="string">"area_code"</span>:<span class="string">"shanghai"</span>,<span class="string">"so2"</span>:<span class="string">"5"</span>,<span class="string">"o3"</span>:<span class="string">"36"</span>,<span class="string">"pm2_5"</span>:<span class="string">"49"</span>,<span class="string">"primary_pollutant"</span>:<span class="string">"颗粒物(PM2.5)"</span>,<span class="string">"co"</span>:<span class="string">"0.7"</span>,<span class="string">"num"</span>:<span class="string">"231"</span>,<span class="string">"no2"</span>:<span class="string">"71"</span>,<span class="string">"quality"</span>:<span class="string">"良好"</span>,<span class="string">"aqi"</span>:<span class="string">"68"</span>,<span class="string">"pm10"</span>:<span class="string">"57"</span>,<span class="string">"o3_8h"</span>:<span class="string">"52"</span>,<span class="string">"time"</span>:<span class="string">"2021-04-27 20:40:10.642"</span>}]}</span><br><span class="line">{<span class="string">"code"</span>:<span class="number">200</span>,<span class="string">"msg"</span>:<span class="string">"success"</span>,<span class="string">"newslist"</span>:[{<span class="string">"area"</span>:<span class="string">"上海"</span>,<span class="string">"area_code"</span>:<span class="string">"shanghai"</span>,<span class="string">"so2"</span>:<span class="string">"5"</span>,<span class="string">"o3"</span>:<span class="string">"36"</span>,<span class="string">"pm2_5"</span>:<span class="string">"49"</span>,<span class="string">"primary_pollutant"</span>:<span class="string">"颗粒物(PM2.5)"</span>,<span class="string">"co"</span>:<span class="string">"0.7"</span>,<span class="string">"num"</span>:<span class="string">"231"</span>,<span class="string">"no2"</span>:<span class="string">"71"</span>,<span class="string">"quality"</span>:<span class="string">"良好"</span>,<span class="string">"aqi"</span>:<span class="string">"68"</span>,<span class="string">"pm10"</span>:<span class="string">"57"</span>,<span class="string">"o3_8h"</span>:<span class="string">"52"</span>,<span class="string">"time"</span>:<span class="string">"2021-04-27 20:40:10.642"</span>}]}</span><br></pre></td></tr></tbody></table></figure>


<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">r = requests.get(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line">print(r.status_code)  <span class="comment"># 检测请求网页的状态码</span></span><br><span class="line"><span class="comment"># 输出200</span></span><br><span class="line">r.encoding = <span class="string">'utf-8'</span></span><br><span class="line">print(r.text)</span><br><span class="line"><span class="comment"># 输出网页内容</span></span><br></pre></td></tr></tbody></table></figure>

<p>通用框架</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()  <span class="comment"># 如果状态不是200，引发HTTPError异常</span></span><br><span class="line">        r.encoding = r.apparent_encoding  <span class="comment"># 使得返回内容的解码是正确的</span></span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"产生异常"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    url = <span class="string">"http://www.baidu.com"</span></span><br><span class="line">    print(getHTMLText(url))</span><br></pre></td></tr></tbody></table></figure>

<p>request使用代理<br>很多网站如果发现同一个IP发出的大量请求，就会封禁这样的IP<br>爬虫为了避免被封IP，必须不断地更换IP地址发出请求，这个时候就需要使用代理</p>
<p>requests库有一个代理参数proxies可以指定通过代理服务器发起请求<br>proxies参数是一个字典，里面包含了http和https的代理URL</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不使用代理</span></span><br><span class="line">resp = requests.get(<span class="string">'http://httpbin.org/ip'</span>)</span><br><span class="line">print(resp.text)</span><br><span class="line"><span class="comment"># {"origin": "114.93.163.248"}</span></span><br><span class="line"></span><br><span class="line">proxies = {</span><br><span class="line">    <span class="string">'http'</span>: <span class="string">'http://139.227.252.141:8118'</span>,</span><br><span class="line">    <span class="string">'https'</span>: <span class="string">'https://139.227.252.141:8118'</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用代理</span></span><br><span class="line">resp = requests.get(<span class="string">'http://httpbin.org/ip'</span>, proxies=proxies)</span><br><span class="line">print(resp.text)</span><br><span class="line"><span class="comment"># {"origin": "139.227.252.141"}</span></span><br></pre></td></tr></tbody></table></figure>

<p>需求1：爬取搜狗首页的页面数据</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 第一步：指定url</span></span><br><span class="line">    url = <span class="string">'https://www.sogou.com/'</span></span><br><span class="line">    <span class="comment"># 第二步：发起请求</span></span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    <span class="comment"># 第三步：获取响应数据</span></span><br><span class="line">    page_text = response.text</span><br><span class="line">    <span class="comment"># print(page_text)</span></span><br><span class="line">    <span class="comment"># 第四步：持久化存储</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'./搜狗首页.html'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)<span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(page_text)</span><br><span class="line">    print(<span class="string">'爬取结束'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>需求2：实现一个简易的网页采集器（爬取搜狗指定词条对应的搜索结果页面）<br>UA伪装：门户网站的服务器会检测载体身份标识，如果检测到是爬虫发起就会拒绝访问，所以需要伪装成正常的浏览器访问身份。</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    url = <span class="string">'https://www.sogou.com/web'</span></span><br><span class="line">    <span class="comment"># 处理url携带的参数：封装到字典中</span></span><br><span class="line">    keyWord = input(<span class="string">'请输入关键字：'</span>)</span><br><span class="line">    param = {</span><br><span class="line">        <span class="string">'query'</span>: keyWord</span><br><span class="line">    }</span><br><span class="line">    headers = {</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36 Edg/88.0.705.56'</span></span><br><span class="line">    }</span><br><span class="line">    response = requests.get(url=url, params=param, headers=headers)</span><br><span class="line">    page_text = response.text</span><br><span class="line">    filename = <span class="string">'./简易网页采集/'</span> + keyWord + <span class="string">'.html'</span></span><br><span class="line">    <span class="keyword">with</span> open(filename, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(page_text)</span><br><span class="line">    print(keyWord + <span class="string">'  保存成功！'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>需求3：破解百度翻译<br>注意：响应数据为json类型；请求方式为POST</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    url = <span class="string">'https://fanyi.baidu.com/sug'</span></span><br><span class="line">    keyWord = input(<span class="string">'请输入关键字：'</span>)</span><br><span class="line">    data = {</span><br><span class="line">        <span class="string">'kw'</span>: keyWord</span><br><span class="line">    }</span><br><span class="line">    headers = {</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36 Edg/88.0.705.56'</span></span><br><span class="line">    }</span><br><span class="line">    response = requests.post(url=url, data=data, headers=headers)</span><br><span class="line">    page_json = response.json()</span><br><span class="line">    <span class="comment"># print(page_json)</span></span><br><span class="line">    fp = open(<span class="string">'./百度翻译/'</span> + keyWord + <span class="string">".json"</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    json.dump(page_json, fp=fp, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">    print(<span class="string">'翻译结束！已保存'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>需求4：爬取豆瓣电影分类排行榜</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    url = <span class="string">'https://movie.douban.com/j/chart/top_list'</span></span><br><span class="line">    num = input(<span class="string">'请输入前多少名数据:'</span>)</span><br><span class="line">    param = {</span><br><span class="line">        <span class="string">'type'</span>: <span class="string">'11'</span>,</span><br><span class="line">        <span class="string">'interval_id'</span>: <span class="string">'100:90'</span>,</span><br><span class="line">        <span class="string">'action'</span>: <span class="string">''</span>,</span><br><span class="line">        <span class="string">'start'</span>: <span class="string">'0'</span>,</span><br><span class="line">        <span class="string">'limit'</span>: num</span><br><span class="line">    }</span><br><span class="line">    headers = {</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36 Edg/88.0.705.56'</span></span><br><span class="line">    }</span><br><span class="line">    response = requests.get(url=url, params=param, headers=headers)</span><br><span class="line">    list_data = response.json()</span><br><span class="line">    fp = open(<span class="string">'./豆瓣排行/豆瓣排行.json'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    json.dump(list_data, fp=fp, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">    print(<span class="string">'保存完成'</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>需求5：肯德基餐厅查询（<a target="_blank" rel="noopener" href="http://www.kfc.com.cn/kfccda/storelist/index.aspx%EF%BC%89">http://www.kfc.com.cn/kfccda/storelist/index.aspx）</a></p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    url = <span class="string">'http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx'</span></span><br><span class="line">    cname = input(<span class="string">'请输入城市：'</span>)</span><br><span class="line">    keyword = input(<span class="string">'请输入关键字：'</span>)</span><br><span class="line">    op = <span class="string">'keyword'</span></span><br><span class="line">    param = {</span><br><span class="line">        <span class="string">'op'</span>: op</span><br><span class="line">    }</span><br><span class="line">    data = {</span><br><span class="line">        <span class="string">'cname'</span>: cname,</span><br><span class="line">        <span class="string">'pid'</span>: <span class="string">''</span>,</span><br><span class="line">        <span class="string">'keyword'</span>: keyword,</span><br><span class="line">        <span class="string">'pageIndex'</span>: <span class="string">'1'</span>,</span><br><span class="line">        <span class="string">'pageSize'</span>: <span class="string">'10'</span></span><br><span class="line">    }</span><br><span class="line">    headers = {</span><br><span class="line">        <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.96 Safari/537.36 Edg/88.0.705.56'</span></span><br><span class="line">    }</span><br><span class="line">    response = requests.post(url=url, data=data, headers=headers, params=param)</span><br><span class="line">    print(response.json())</span><br><span class="line">    table_data = response.json()</span><br><span class="line">    fp = open(<span class="string">'./肯德基餐厅/'</span>+cname+<span class="string">'_'</span>+keyword+<span class="string">'.json'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    json.dump(table_data, fp=fp, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">    print(<span class="string">'保存完成'</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">URL_GET = <span class="string">"https://api.douban.com/v2/event/list"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">use_params_requests</span>():</span></span><br><span class="line">    <span class="comment"># 构建请求参数</span></span><br><span class="line">    params = {<span class="string">'loc'</span>: <span class="string">'108288'</span>, <span class="string">'day_type'</span>: <span class="string">'weekend'</span>, <span class="string">'type'</span>: <span class="string">'exhibition'</span>}</span><br><span class="line">    <span class="comment"># 发送请求</span></span><br><span class="line">    response = requests.get(URL_GET, params=params)</span><br><span class="line">    <span class="comment"># 处理响应</span></span><br><span class="line">    print(<span class="string">'&gt;&gt;&gt;&gt;&gt;&gt;Response Headers:'</span>)</span><br><span class="line">    print(response.headers)</span><br><span class="line">    print(<span class="string">'&gt;&gt;&gt;&gt;&gt;&gt;Status Code:'</span>)</span><br><span class="line">    print(response.status_code)</span><br><span class="line">    print(<span class="string">'&gt;&gt;&gt;&gt;&gt;&gt;&gt;Response Body:'</span>)</span><br><span class="line">    print(response.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Use params requests:'</span>)</span><br><span class="line">    use_params_requests()</span><br></pre></td></tr></tbody></table></figure>

<p>网络图片爬取及存储</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''r.content  #表示返回内容的二进制格式'''</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">new_folder = <span class="string">'./Picture/'</span>  <span class="comment"># 相对路径</span></span><br><span class="line">url = <span class="string">'http://img0.dili360.com/ga/M00/02/AB/wKgBzFQ26i2AWujSAA_-xvEYLbU441.jpg@!rw9'</span></span><br><span class="line">path = new_folder + url.split(<span class="string">'/'</span>)[<span class="number">-1</span>].split(<span class="string">'@'</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(new_folder):</span><br><span class="line">        os.mkdir(new_folder)  <span class="comment"># 创建新目录</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line"></span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        <span class="comment"># 如何将二进制转化为图片保存</span></span><br><span class="line">        <span class="keyword">with</span> open(path, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="comment"># 新建wKgBzFQ26i2AWujSAA_-xvEYLbU441.jpg</span></span><br><span class="line">            f.write(r.content)</span><br><span class="line">            f.close()</span><br><span class="line">            print(<span class="string">'图片保存成功'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">'文件已存在'</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>百度/360搜索关键字</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#实例3：爬取搜索页面</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    kw = {<span class="string">'wd'</span>: <span class="string">'python'</span>}</span><br><span class="line">    r = requests.get(<span class="string">'https://www.baidu.com/s'</span>, params=kw)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    print(len(r.text))  <span class="comment"># 227</span></span><br><span class="line">    <span class="comment"># r.request.url  返回的是百度安全验证的链接？</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    kw = {<span class="string">'q'</span>: <span class="string">'python'</span>}  <span class="comment"># 360搜索的关键字的键为q</span></span><br><span class="line">    r = requests.get(<span class="string">'https://www.so.com/s'</span>, params=kw)</span><br><span class="line">    r.raise_for_status()</span><br><span class="line">    r.encoding = r.apparent_encoding</span><br><span class="line">    print(len(r.text))  <span class="comment">#257468</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"爬取失败"</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>添加headers和查询参数</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">kw = {<span class="string">'wd'</span>:<span class="string">'python'</span>}</span><br><span class="line">headers = {<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36'</span>}</span><br><span class="line"></span><br><span class="line"><span class="comment"># params 接收一个字典或者字符串的查询参数，字典类型自动转换为url编码，不需要urlencode()</span></span><br><span class="line">response = requests.get(<span class="string">"http://www.baidu.com/s?"</span>, params = kw, headers = headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应内容，response.text 返回的是Unicode格式的数据</span></span><br><span class="line"><span class="keyword">print</span> response.text</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应内容，response.content返回的字节流数据</span></span><br><span class="line"><span class="keyword">print</span> response.content</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看完整url地址</span></span><br><span class="line"><span class="keyword">print</span> response.url</span><br><span class="line"></span><br><span class="line"><span class="comment"># # 查看响应头部字符编码</span></span><br><span class="line"><span class="keyword">print</span> response.encoding</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应码</span></span><br><span class="line"><span class="keyword">print</span> response.status_code</span><br></pre></td></tr></tbody></table></figure>

<p>使用代理</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = {<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36'</span>}</span><br><span class="line"><span class="comment"># 根据协议类型，选择不同的代理</span></span><br><span class="line">proxies = {</span><br><span class="line">  <span class="string">"http"</span>: <span class="string">"http://119.28.152.208:80"</span>,</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">"http://www.baidu.com/"</span>, proxies = proxies,headers=headers)</span><br><span class="line"><span class="keyword">print</span> response.text</span><br></pre></td></tr></tbody></table></figure>

<p>私密代理验证</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">headers = {<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36'</span>}</span><br><span class="line"></span><br><span class="line">proxy = { <span class="string">"http"</span>: <span class="string">"name:pwd@ip:port"</span> }</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">"http://www.baidu.com/"</span>, proxies = proxy,headers=headers)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> response.text</span><br></pre></td></tr></tbody></table></figure>

<p>web客户端验证</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">auth=(<span class="string">'test'</span>, <span class="string">'123456'</span>)</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">'http://192.168.xxx.xx'</span>, auth = auth)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> response.text</span><br></pre></td></tr></tbody></table></figure>

<p>session</p>
<p>在 requests 里，session对象是一个非常常用的对象，这个对象代表一次用户会话：从客户端浏览器连接服务器开始，到客户端浏览器与服务器断开。</p>
<p>会话能让我们在跨请求时候保持某些参数，比如在同一个 Session 实例发出的所有请求之间保持 cookie 。</p>
<figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># _*_ coding:utf-8 _*_</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 创建session对象，可以保存Cookie值</span></span><br><span class="line">ssion = requests.session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 处理 headers</span></span><br><span class="line">headers = {<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36'</span>}</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 需要登录的用户名和密码</span></span><br><span class="line">data = {<span class="string">"email"</span>:<span class="string">"158xxxxxxxx"</span>, <span class="string">"password"</span>:<span class="string">"pythonxxxxxxx"</span>}</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 发送附带用户名和密码的请求，并获取登录后的Cookie值，保存在ssion里</span></span><br><span class="line">ssion.post(<span class="string">"http://www.renren.com/PLogin.do"</span>, data = data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. ssion包含用户登录后的Cookie值，可以直接访问那些登录后才可以访问的页面</span></span><br><span class="line">response = ssion.get(<span class="string">"http://zhibo.renren.com/news/108"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 打印响应内容</span></span><br><span class="line"><span class="keyword">print</span> response.text</span><br></pre></td></tr></tbody></table></figure><script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/08/21/socket/" rel="prev" title="socket">
                  <i class="fa fa-chevron-left"></i> socket
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2020/08/21/replace/" rel="next" title="replace">
                  replace <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">外心人D</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  




  





</body>
</html>
